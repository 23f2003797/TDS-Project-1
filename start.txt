### Directory structure:
# tds_virtual_ta/
# ├── app/
# │   ├── main.py
# │   ├── qa_engine.py
# │   └── utils.py
# ├── scrape/
# │   └── scrape_discourse.py
# ├── data/
# ├── requirements.txt
# ├── LICENSE
# └── README.md

### app/main.py
from fastapi import FastAPI, Request
from pydantic import BaseModel
from app.qa_engine import answer_question
import base64
import io
from PIL import Image
import pytesseract

app = FastAPI()

class QuestionInput(BaseModel):
    question: str
    image: str | None = None

@app.post("/api/")
async def get_answer(input_data: QuestionInput):
    extracted_text = ""
    if input_data.image:
        image_data = base64.b64decode(input_data.image)
        image = Image.open(io.BytesIO(image_data))
        extracted_text = pytesseract.image_to_string(image)
    
    final_question = input_data.question + "\n" + extracted_text
    answer, links = answer_question(final_question)
    return {"answer": answer, "links": links}


### app/qa_engine.py
from app.utils import load_data, get_relevant_chunks, generate_answer

# Preload data and embeddings
course_data = load_data("data/course_content.json")
discourse_data = load_data("data/discourse_posts.json")
all_docs = course_data + discourse_data

# Main answer generator
def answer_question(question: str):
    top_chunks = get_relevant_chunks(question, all_docs)
    answer = generate_answer(question, top_chunks)
    links = [chunk["link"] for chunk in top_chunks if "link" in chunk]
    return answer, [{"url": l, "text": "Relevant link"} for l in links[:2]]


### app/utils.py
import json
from sentence_transformers import SentenceTransformer, util
import openai

model = SentenceTransformer("all-MiniLM-L6-v2")
openai.api_key = "YOUR_OPENAI_API_KEY"

def load_data(path):
    with open(path, 'r') as f:
        return json.load(f)

def get_relevant_chunks(question, docs, top_k=3):
    question_emb = model.encode(question, convert_to_tensor=True)
    doc_embeddings = [model.encode(doc['text'], convert_to_tensor=True) for doc in docs]
    scores = [float(util.pytorch_cos_sim(question_emb, emb)) for emb in doc_embeddings]
    sorted_docs = sorted(zip(scores, docs), key=lambda x: x[0], reverse=True)
    return [doc for _, doc in sorted_docs[:top_k]]

def generate_answer(question, contexts):
    context_text = "\n---\n".join([doc['text'] for doc in contexts])
    prompt = f"Answer the question based on the context below:\n{context_text}\n\nQuestion: {question}\nAnswer:"
    res = openai.ChatCompletion.create(
        model="gpt-3.5-turbo-0125",
        messages=[{"role": "user", "content": prompt}]
    )
    return res['choices'][0]['message']['content'].strip()


### scrape/scrape_discourse.py
import requests
import json
from datetime import datetime

BASE_URL = "https://discourse.onlinedegree.iitm.ac.in"
CATEGORY = "/c/tools-in-data-science"


def fetch_posts(start_date, end_date):
    results = []
    page = 0
    while True:
        page += 1
        r = requests.get(f"{BASE_URL}{CATEGORY}.json?page={page}")
        if not r.ok: break
        data = r.json()
        for topic in data.get("topic_list", {}).get("topics", []):
            created = datetime.strptime(topic['created_at'][:10], "%Y-%m-%d")
            if start_date <= created <= end_date:
                results.append({
                    "id": topic['id'],
                    "title": topic['title'],
                    "link": f"{BASE_URL}/t/{topic['slug']}/{topic['id']}",
                    "text": topic['title'] + ". " + topic.get("excerpt", "")
                })
        if page > 5: break  # prevent overload
    with open("data/discourse_posts.json", "w") as f:
        json.dump(results, f, indent=2)


if __name__ == "__main__":
    fetch_posts(datetime(2025, 1, 1), datetime(2025, 4, 14))


### requirements.txt
fastapi
uvicorn
pillow
pytesseract
sentence-transformers
openai
requests
python-multipart


### LICENSE
MIT License

Copyright (c) 2025

Permission is hereby granted, free of charge, to any person obtaining a copy...

# (standard MIT license text continues)


### README.md
# TDS Virtual TA

An automated Teaching Assistant for the IITM TDS course.

## Features
- Answer questions based on course content & Discourse discussions
- Supports screenshot-based questions (OCR)
- Simple API endpoint using FastAPI

## Usage
```bash
curl "https://app.example.com/api/" \
  -H "Content-Type: application/json" \
  -d '{"question": "Should I use gpt-4o-mini which AI proxy supports, or gpt3.5 turbo?", "image": "$(base64 -w0 example.webp)"}'
```

## Run locally
```bash
uvicorn app.main:app --reload
```

---

Let me know if you want this pushed to GitHub, or help with deployment!
